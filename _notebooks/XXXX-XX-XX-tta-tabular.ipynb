{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test-Time Augmentation for Tabular Data\n",
    "> Improving predictive performance during inference\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Nikita Kozodoi\n",
    "- categories: [python, structured data, test-time augmentation]\n",
    "- image: images/posts/tta_tabular.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test time augmentation (TTA) is a popular data augmentation technique in computer vision. TTA aims at boosting the predictive performance of a model. The idea behind TTA is to perform random modifications to the test images on the inference stage and average model predictions over multiple versions of the same image.\n",
    "\n",
    "This blogpost explores the opportunities to use TTA in the structured data environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementing TTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining TTA for tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to treat categorical features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing TTA with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-show\n",
    "\n",
    "def predict_proba_with_tta(data, \n",
    "                           model, \n",
    "                           dummies = None, \n",
    "                           num_tta = 4, \n",
    "                           alpha   = 0.01, \n",
    "                           beta    = 0.01, \n",
    "                           seed    = 0):\n",
    "    '''\n",
    "    Predicts class probabilities using TTA.\n",
    "    \n",
    "    Arguments:\n",
    "    - data (numpy array): data set with the feature values \n",
    "    - model (sklearn model): machine learning model\n",
    "    - dummies (list): list of column names of dummy features\n",
    "    - num_tta (integer): number of test-time augmentations\n",
    "    - alpha (float): noise parameter for continuous features\n",
    "    - beta (float): noise parameter for dummy features\n",
    "    - seed (integer): random seed\n",
    "\n",
    "    Returns:\n",
    "    - array of predicted probabilities\n",
    "    '''\n",
    "    \n",
    "    # set random seed\n",
    "    np.random.seed(seed = seed)\n",
    "    \n",
    "    # original prediction\n",
    "    preds = model.predict_proba(data) / (num_tta + 1)\n",
    "     \n",
    "    # select numeric features\n",
    "    num_vars = [var for var in data.columns if data[var].dtype != 'object']\n",
    "        \n",
    "    # find dummies\n",
    "    if dummies != None:\n",
    "        num_vars = list(set(num_vars) - set(dummies))\n",
    "    \n",
    "    # synthetic predictions\n",
    "    for i in range(num_tta):\n",
    "        \n",
    "        # copy data\n",
    "        data_new = data.copy()\n",
    "    \n",
    "        # introduce noise to numeric vars\n",
    "        for var in num_vars:\n",
    "            data_new[var] = data_new[var] + alpha * np.random.normal(0, 1, size = len(data_new)) * data_new[var].std()\n",
    "            \n",
    "        # introduce noise to dummies\n",
    "        if dummies != None:\n",
    "            for var in dummies:\n",
    "                probs = np.random.binomial(1, (1 - beta), size = len(data_new))\n",
    "                data_new.loc[probs == 0, var] = 1 - data_new.loc[probs == 0, var]\n",
    "            \n",
    "        # predict probs\n",
    "        preds_new = model.predict_proba(data_new) \n",
    "        preds    += preds_new / (num_tta + 1)\n",
    "    \n",
    "    # return probs\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Experiments on UCI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates multiple versions of the test data by adding noise to numeric variables. Predictions are averaged across all versions of the test data.\n",
    "\n",
    "Parameters:\n",
    "- X_test = test data as pandas dataframe\n",
    "- model = fitted classifier\n",
    "- dummies = list of dummy variables\n",
    "- n = number of synthetic datasets to create\n",
    "- seed = random seed\n",
    "- alpha = noise level for numeric vars: var_new = var + N(0,1) x alpha x SD(var) \n",
    "- beta = noise level for dummies: var_new = var with Prob = (1 - beta);  var_new = (1 - var) with Prob = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thomas.csv',\n",
       " 'german.csv',\n",
       " 'hmeq.csv',\n",
       " 'bene2.csv',\n",
       " 'lendingclub.csv',\n",
       " 'bene1.csv',\n",
       " 'cashbus.csv',\n",
       " 'uk.csv',\n",
       " 'australian.csv',\n",
       " 'pakdd.csv',\n",
       " 'gmsc.csv',\n",
       " 'paipaidai.csv']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-show\n",
    "\n",
    "# list of datasets\n",
    "datasets = os.listdir('../data')\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-show\n",
    "\n",
    "# classifier\n",
    "clf = RandomForestClassifier(n_estimators = 500, random_state = 1, n_jobs = 4)\n",
    "\n",
    "# settings\n",
    "folds = StratifiedKFold(n_splits     = 5, \n",
    "                        shuffle      = True, \n",
    "                        random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "_uuid": "4e5e1ed34e0887b3c10b8e649abef15f44a34853",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Dataset: thomas.csv (1225, 28)\n",
      "-------------------------------------\n",
      "- AUC before TTA = 0.612322 \n",
      "- AUC with TTA 1 = 0.612152 \n",
      "- AUC with TTA 2 = 0.613617 \n",
      "- AUC with TTA 3 = 0.612190 \n",
      "-------------------------------------\n",
      "\n",
      "-------------------------------------\n",
      "Dataset: german.csv (1000, 61)\n",
      "-------------------------------------\n",
      "- AUC before TTA = 0.796233 \n",
      "- AUC with TTA 1 = 0.796350 \n",
      "- AUC with TTA 2 = 0.796300 \n",
      "- AUC with TTA 3 = 0.796300 \n",
      "-------------------------------------\n",
      "\n",
      "-------------------------------------\n",
      "Dataset: hmeq.csv (5960, 20)\n",
      "-------------------------------------\n",
      "- AUC before TTA = 0.975995 \n",
      "- AUC with TTA 1 = 0.977148 \n",
      "- AUC with TTA 2 = 0.976805 \n",
      "- AUC with TTA 3 = 0.976000 \n",
      "-------------------------------------\n",
      "\n",
      "-------------------------------------\n",
      "Dataset: bene2.csv (7190, 28)\n",
      "-------------------------------------\n",
      "- AUC before TTA = 0.801193 \n",
      "- AUC with TTA 1 = 0.799689 \n",
      "- AUC with TTA 2 = 0.799387 \n",
      "- AUC with TTA 3 = 0.801503 \n",
      "-------------------------------------\n",
      "\n",
      "-------------------------------------\n",
      "Dataset: lendingclub.csv (43344, 114)\n",
      "-------------------------------------\n",
      "- AUC before TTA = 0.625029 \n",
      "- AUC with TTA 1 = 0.626554 \n",
      "- AUC with TTA 2 = 0.628207 \n",
      "- AUC with TTA 3 = 0.625115 \n",
      "-------------------------------------\n",
      "\n",
      "-------------------------------------\n",
      "Dataset: bene1.csv (3123, 84)\n",
      "-------------------------------------\n",
      "- AUC before TTA = 0.788607 \n",
      "- AUC with TTA 1 = 0.789283 \n",
      "- AUC with TTA 2 = 0.789447 \n",
      "- AUC with TTA 3 = 0.788592 \n",
      "-------------------------------------\n",
      "\n",
      "-------------------------------------\n",
      "Dataset: cashbus.csv (15000, 642)\n",
      "-------------------------------------\n",
      "- AUC before TTA = 0.629648 \n",
      "- AUC with TTA 1 = 0.625360 \n",
      "- AUC with TTA 2 = 0.624874 \n",
      "- AUC with TTA 3 = 0.629511 \n",
      "-------------------------------------\n",
      "\n",
      "-------------------------------------\n",
      "Dataset: uk.csv (30000, 51)\n",
      "-------------------------------------\n",
      "- AUC before TTA = 0.712042 \n",
      "- AUC with TTA 1 = 0.721543 \n",
      "- AUC with TTA 2 = 0.723359 \n",
      "- AUC with TTA 3 = 0.712693 \n",
      "-------------------------------------\n",
      "\n",
      "-------------------------------------\n",
      "Dataset: australian.csv (690, 42)\n",
      "-------------------------------------\n",
      "- AUC before TTA = 0.931787 \n",
      "- AUC with TTA 1 = 0.932068 \n",
      "- AUC with TTA 2 = 0.931958 \n",
      "- AUC with TTA 3 = 0.931838 \n",
      "-------------------------------------\n",
      "\n",
      "-------------------------------------\n",
      "Dataset: pakdd.csv (50000, 373)\n",
      "-------------------------------------\n",
      "- AUC before TTA = 0.620081 \n",
      "- AUC with TTA 1 = 0.622018 \n",
      "- AUC with TTA 2 = 0.623080 \n",
      "- AUC with TTA 3 = 0.620159 \n",
      "-------------------------------------\n",
      "\n",
      "-------------------------------------\n",
      "Dataset: gmsc.csv (150000, 68)\n",
      "-------------------------------------\n",
      "- AUC before TTA = 0.846187 \n",
      "- AUC with TTA 1 = 0.856188 \n",
      "- AUC with TTA 2 = 0.855176 \n",
      "- AUC with TTA 3 = 0.847174 \n",
      "-------------------------------------\n",
      "\n",
      "-------------------------------------\n",
      "Dataset: paipaidai.csv (60000, 1934)\n",
      "-------------------------------------\n",
      "- AUC before TTA = 0.716398 \n",
      "- AUC with TTA 1 = 0.716397 \n",
      "- AUC with TTA 2 = 0.721679 \n",
      "- AUC with TTA 3 = 0.716691 \n",
      "-------------------------------------\n",
      "\n",
      "-------------------------------------\n",
      "Finished in 206.1 minutes\n",
      "-------------------------------------\n",
      "TTA 1 improves AUC in 8/12 cases\n",
      "Mean AUC change = 0.001602\n",
      "-------------------------------------\n",
      "TTA 2 improves AUC in 10/12 cases\n",
      "Mean AUC change = 0.002364\n",
      "-------------------------------------\n",
      "TTA 3 improves AUC in 9/12 cases\n",
      "Mean AUC change = 0.000187\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#collapse-show\n",
    "\n",
    "# placeholders\n",
    "auc_change = []\n",
    "\n",
    "# timer\n",
    "start = time.time()\n",
    "\n",
    "# modeling loop\n",
    "for data in datasets:\n",
    "\n",
    "    ##### DATA PREPARATION\n",
    "\n",
    "    # import data\n",
    "    X = pd.read_csv('../data/' + data)\n",
    "\n",
    "    # convert target to integer\n",
    "    X.loc[X.BAD == 'BAD',  'BAD'] = 1\n",
    "    X.loc[X.BAD == 'GOOD', 'BAD'] = 0\n",
    "\n",
    "    # extract X and y\n",
    "    y = X['BAD']\n",
    "    del X['BAD']\n",
    "\n",
    "    # create dummies\n",
    "    X = pd.get_dummies(X, prefix_sep = '_dummy_')\n",
    "\n",
    "    # data information\n",
    "    print('-------------------------------------')\n",
    "    print('Dataset:', data, X.shape)\n",
    "    print('-------------------------------------')\n",
    "\n",
    "    \n",
    "    ##### CROSS-VALIDATION\n",
    "    \n",
    "    # create objects\n",
    "    oof_preds_raw = np.zeros((len(X), y.nunique()))\n",
    "    oof_preds_tta = np.zeros((len(X), y.nunique()))\n",
    "\n",
    "    # modeling loop\n",
    "    for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "\n",
    "        # data partitioning\n",
    "        trn_x, trn_y = X.iloc[trn_], y.iloc[trn_]\n",
    "        val_x, val_y = X.iloc[val_], y.iloc[val_]\n",
    "\n",
    "        # train the model\n",
    "        clf.fit(trn_x, trn_y)\n",
    "        \n",
    "        # identify dummies\n",
    "        dummies = list(X.filter(like = '_dummy_').columns)\n",
    "\n",
    "        # predictions\n",
    "        oof_preds_raw[val_, :] =  clf.predict_proba(val_x)\n",
    "        oof_preds_tta[val_, :] =  predict_proba_with_tta(data    = val_x, \n",
    "                                                         model   = clf, \n",
    "                                                         dummies = dummies,\n",
    "                                                         num_tta = 5, \n",
    "                                                         alpha   = np.sqrt(len(trn_x)) / 3000,\n",
    "                                                         beta    = np.sqrt(len(trn_x)) / 30000,\n",
    "                                                         seed    = 1)\n",
    "\n",
    "    # print performance\n",
    "    print('- AUC before TTA = %.6f ' % roc_auc_score(y, oof_preds_raw[:,1]))\n",
    "    print('- AUC with TTA   = %.6f ' % roc_auc_score(y, oof_preds_tta[:,1]))\n",
    "    print('-------------------------------------')\n",
    "    print('')\n",
    "    \n",
    "    # save AUC delta\n",
    "    delta = roc_auc_score(y, oof_preds_tta[:,1]) - roc_auc_score(y, oof_preds_raw[:,1])\n",
    "    auc_change.append(delta)\n",
    "\n",
    "# display results\n",
    "print('-------------------------------------')\n",
    "print('Finished in %.1f minutes' % ((time.time() - start) / 60))\n",
    "print('-------------------------------------')\n",
    "print('TTA improves AUC in %.0f/%.0f cases' % (np.sum(np.array(auc_change) > 0), len(datasets)))\n",
    "print('Mean AUC change = %.6f' % np.mean(auc_change))\n",
    "print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "\n",
    "objects = list(range(len(datasets)))\n",
    "y_pos   = np.arange(len(objects))\n",
    "perf    = np.sort(auc_change2)\n",
    "\n",
    "plt.figure(figsize = (6, 8))\n",
    "plt.barh(y_pos, perf, align = 'center', color = 'blue', alpha = 0.66)\n",
    "\n",
    "plt.ylabel('Dataset')\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('AUC Gain')\n",
    "plt.title('')\n",
    "ax.plot([0, 0], [1, 12], 'k--')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}